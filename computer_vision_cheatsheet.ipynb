{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c682e875",
   "metadata": {},
   "source": [
    "# COMPUTER VISION ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10dacb",
   "metadata": {},
   "source": [
    "This cheat sheet covers fundamental concepts in Computer Vision (CV) using PyTorch and Torchvision.\n",
    "It provides explanations and runnable examples for image classification and transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3fb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FakeData\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613eb45",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================\n",
    "# 1. Core Computer Vision Components\n",
    "#==================================\n",
    "print(\"# --- Core Computer Vision Components ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convolutional Layer (nn.Conv2d) ---\n",
    "# The heart of modern CV models. It applies a set of learnable filters to an input image.\n",
    "# These filters are small matrices that slide over the image to detect features like edges,\n",
    "# corners, and textures.\n",
    "# - in_channels: Number of channels in the input image (e.g., 3 for RGB).\n",
    "# - out_channels: Number of filters to apply. Each filter learns a different feature.\n",
    "# - kernel_size: The dimensions of the filter (e.g., 3x3 or 5x5).\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "print(f\"Example Conv2d Layer: {conv_layer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3786e3f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Pooling Layer (nn.MaxPool2d) ---\n",
    "# Pooling layers are used to downsample the feature maps, reducing their spatial dimensions.\n",
    "# This reduces the number of parameters and computation in the network, and also helps\n",
    "# to make the detected features more robust to changes in position.\n",
    "# - kernel_size: The size of the window to take a max over.\n",
    "pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "print(f\"Example MaxPool2d Layer: {pool_layer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21afeaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================\n",
    "# 2. Complete Example: Training an Image Classifier\n",
    "#==================================\n",
    "print(\"\\n# --- A Complete Image Classification Example ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Prepare the Data ---\n",
    "# `torchvision.transforms` provides common image transformations.\n",
    "# - ToTensor(): Converts a PIL Image or numpy.ndarray to a FloatTensor and scales the image's\n",
    "#   pixel intensity values in the range [0., 1.].\n",
    "# - Normalize(): Normalizes a tensor image with mean and standard deviation. This helps\n",
    "#   the model train more effectively.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Mean and std for 3 channels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4564f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use `FakeData` for this example. It generates random tensors, which is perfect\n",
    "# for demonstrating the training loop without needing to download a large dataset.\n",
    "# For a real dataset, you would use `torchvision.datasets.CIFAR10` or `ImageFolder`.\n",
    "train_dataset = FakeData(size=1000, image_size=(3, 32, 32), num_classes=10, transform=transform)\n",
    "test_dataset = FakeData(size=200, image_size=(3, 32, 32), num_classes=10, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea415b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `DataLoader` takes a dataset and provides an iterable over it, with options for\n",
    "# batching, shuffling, and parallel data loading.\n",
    "# - batch_size: How many samples per batch to load.\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "print(\"Data loaded and prepared using FakeData and DataLoader.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43ca36",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Step 2: Define the Convolutional Neural Network (CNN) ---\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # The convolutional part of the network\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), # -> 16x32x32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),      # -> 16x16x16\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),# -> 32x16x16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)       # -> 32x8x8\n",
    "        )\n",
    "        # The classifier part of the network\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 8 * 8, 128), # Flatten the 32x8x8 feature map\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten the feature map to feed into the classifier\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbaeca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "print(f\"CNN Architecture:\\n{model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a045f2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Step 3: Define Loss and Optimizer ---\n",
    "criterion = nn.CrossEntropyLoss() # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e13a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: The Training Loop ---\n",
    "epochs = 3 # Use a small number of epochs for this demonstration\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Move data to the selected device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d55e0d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Finished Training.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Evaluate the Model ---\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeff1b9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f'Accuracy of the network on the {len(test_dataset)} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cf8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================\n",
    "# 3. Transfer Learning\n",
    "#==================================\n",
    "print(\"\\n# --- Transfer Learning Example ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a635166b",
   "metadata": {},
   "source": [
    "Transfer learning is a technique where a model pre-trained on a large dataset (like ImageNet)\n",
    "is used as the starting point for a new task. This is highly effective as the pre-trained\n",
    "model has already learned rich feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e41b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Load a Pre-trained Model ---\n",
    "# We'll load ResNet-18, a popular CNN architecture, with weights pre-trained on ImageNet.\n",
    "model_tl = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16712da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Freeze Pre-trained Layers ---\n",
    "# We \"freeze\" the weights of the pre-trained layers so they don't get updated during training.\n",
    "# This ensures we don't lose the learned features.\n",
    "for param in model_tl.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Replace the Final Layer ---\n",
    "# The final layer of the pre-trained model is specific to its original task (e.g., 1000 classes for ImageNet).\n",
    "# We replace it with a new layer that is tailored to our new task (e.g., 10 classes for CIFAR-10).\n",
    "num_ftrs = model_tl.fc.in_features  # Get the number of input features of the final layer\n",
    "model_tl.fc = nn.Linear(num_ftrs, 10) # Create a new final layer for 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff093932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, only the weights of this new final layer will be trained.\n",
    "model_tl = model_tl.to(device)\n",
    "print(\"ResNet-18 model loaded and modified for transfer learning.\")\n",
    "print(\"The final fully connected layer has been replaced.\")\n",
    "# This `model_tl` can now be trained using a similar training loop as above."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
